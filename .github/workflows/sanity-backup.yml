name: Sanity Daily Backup

on:
  schedule:
    - cron: '0 3 * * *'  # Daily at 3:00 AM UTC
  workflow_dispatch:      # Manual trigger

jobs:
  prepare:
    runs-on: ubuntu-latest
    outputs:
      markets: ${{ steps.set-markets.outputs.markets }}
    steps:
      - name: Set markets matrix
        id: set-markets
        run: |
          echo 'markets=${{ secrets.SANITY_MARKETS }}' >> $GITHUB_OUTPUT

  backup:
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      matrix:
        market: ${{ fromJson(needs.prepare.outputs.markets) }}
      fail-fast: false  # Continue even if one market fails
      max-parallel: 5   # Maximum 5 markets processed simultaneously
    
    name: Backup ${{ matrix.market.market }}
    
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Create backup script
        run: |
          cat > backup.js << 'ENDOFFILE'
          import https from 'https';
          import fs from 'fs';
          import path from 'path';
          import { createWriteStream } from 'fs';
          import { pipeline } from 'stream/promises';
          
          const PROJECT_ID = process.env.SANITY_PROJECT_ID;
          const TOKEN = process.env.SANITY_TOKEN;
          const DATASET = 'production';
          
          async function downloadFile(url, dest) {
            return new Promise((resolve, reject) => {
              https.get(url, (response) => {
                if (response.statusCode === 302 || response.statusCode === 301) {
                  downloadFile(response.headers.location, dest).then(resolve).catch(reject);
                  return;
                }
                const file = createWriteStream(dest);
                response.pipe(file);
                file.on('finish', () => {
                  file.close();
                  resolve();
                });
                file.on('error', (err) => {
                  fs.unlink(dest, () => reject(err));
                });
              }).on('error', reject);
            });
          }
          
          async function exportData() {
            console.log('Exporting documents...');
            
            // Export documents via Sanity HTTP API
            const exportUrl = `https://${PROJECT_ID}.api.sanity.io/v1/data/export/${DATASET}`;
            
            await new Promise((resolve, reject) => {
              https.get(exportUrl, {
                headers: { 'Authorization': `Bearer ${TOKEN}` }
              }, (response) => {
                const file = createWriteStream('data.ndjson');
                response.pipe(file);
                file.on('finish', () => {
                  file.close();
                  console.log('Documents exported successfully');
                  resolve();
                });
                file.on('error', reject);
              }).on('error', reject);
            });
            
            // Parse documents and extract asset references
            console.log('Parsing assets...');
            const data = fs.readFileSync('data.ndjson', 'utf8');
            const lines = data.split('\n').filter(line => line.trim());
            
            const assetRefs = new Set();
            for (const line of lines) {
              try {
                const doc = JSON.parse(line);
                const jsonStr = JSON.stringify(doc);
                
                // Find all image asset references
                const matches = jsonStr.matchAll(/"_ref":"(image-[a-f0-9]+-\d+x\d+-[a-z]+)"/g);
                for (const match of matches) {
                  assetRefs.add(match[1]);
                }
              } catch (e) {
                // Skip invalid lines
              }
            }
            
            console.log(`Found ${assetRefs.size} unique assets`);
            
            // Create assets directory
            if (!fs.existsSync('assets')) {
              fs.mkdirSync('assets');
            }
            
            // Download all assets from CDN
            let downloaded = 0;
            for (const ref of assetRefs) {
              try {
                // Convert ref to CDN URL: image-abc123-1920x1080-jpg -> abc123-1920x1080.jpg
                const parts = ref.replace('image-', '').split('-');
                const hash = parts[0];
                const dimensions = parts[1];
                const ext = parts[2];
                const filename = `${hash}-${dimensions}.${ext}`;
                const url = `https://cdn.sanity.io/images/${PROJECT_ID}/${DATASET}/${filename}`;
                
                await downloadFile(url, path.join('assets', filename));
                downloaded++;
                if (downloaded % 10 === 0) {
                  console.log(`Downloaded ${downloaded}/${assetRefs.size} assets...`);
                }
              } catch (err) {
                console.error(`Failed to download ${ref}: ${err.message}`);
              }
            }
            
            console.log(`Successfully downloaded ${downloaded} assets`);
          }
          
          exportData().catch(console.error);
          ENDOFFILE
          
          # Create minimal package.json for ES modules support
          echo '{"type": "module"}' > package.json

      - name: Run backup
        run: |
          node backup.js
          
          # Create archive with market name and timestamp
          BACKUP_DATE=$(date +%Y-%m-%d_%H-%M-%S)
          MARKET_NAME="${{ matrix.market.market }}"
          MARKET_SLUG=$(echo "$MARKET_NAME" | tr '[:upper:]' '[:lower:]' | tr ' ' '-')
          tar -czf sanity-backup-${MARKET_SLUG}-${BACKUP_DATE}.tar.gz data.ndjson assets/
          
          echo "‚úÖ Backup completed for $MARKET_NAME!"
          ls -lh sanity-backup-*.tar.gz
          du -sh assets/ 2>/dev/null || echo "No assets found"
        env:
          SANITY_PROJECT_ID: ${{ matrix.market.id }}
          SANITY_TOKEN: ${{ matrix.market.key }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Upload to S3
        run: |
          # Find backup file (with timestamp in name)
          BACKUP_FILE=$(ls sanity-backup-*.tar.gz)
          MARKET_NAME="${{ matrix.market.market }}"
          MARKET_SLUG=$(echo "$MARKET_NAME" | tr '[:upper:]' '[:lower:]' | tr ' ' '-')
          
          echo "Uploading ${BACKUP_FILE} to S3..."
          
          # Upload to market-specific folder
          aws s3 cp ${BACKUP_FILE} s3://${{ secrets.S3_BUCKET }}/backups/${MARKET_SLUG}/${BACKUP_FILE}
          
          echo "‚úÖ Backup for $MARKET_NAME successfully uploaded to S3!"
          echo "üìç Location: s3://${{ secrets.S3_BUCKET }}/backups/${MARKET_SLUG}/${BACKUP_FILE}"
